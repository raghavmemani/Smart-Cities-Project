{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras_preprocessing\n",
    "from keras_preprocessing import image\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing The Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 980 images belonging to 2 classes.\n",
      "Found 239 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define directories\n",
    "TRAINING_DIR = \"Datasets/Training\"\n",
    "VALIDATION_DIR = \"Datasets/Validation\"\n",
    "\n",
    "# Define the data generators\n",
    "training_datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True, rotation_range=30, height_shift_range=0.2, fill_mode='nearest')\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow images from directories\n",
    "train_generator = training_datagen.flow_from_directory(\n",
    "    TRAINING_DIR,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    VALIDATION_DIR,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rakeem Shaikh\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">34,944</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">614,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,457,984</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,147,776</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,050</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │        \u001b[38;5;34m34,944\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m614,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m384\u001b[0m)      │     \u001b[38;5;34m2,457,984\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m384\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1536\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1536\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │     \u001b[38;5;34m3,147,776\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m2,098,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │         \u001b[38;5;34m2,050\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,355,586</span> (31.87 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,355,586\u001b[0m (31.87 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,355,586</span> (31.87 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,355,586\u001b[0m (31.87 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(96, (11,11), strides=(4,4), activation='relu', input_shape=(224, 224, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n",
    "    tf.keras.layers.Conv2D(256, (5,5), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n",
    "    tf.keras.layers.Conv2D(384, (5,5), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(2048, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Dense(1024, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = len(train_generator)\n",
    "validation_steps = len(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[[[0.94117653, 0.9333334 , 0.8352942 ],\n",
      "         [0.90196085, 0.8588236 , 0.78823537],\n",
      "         [0.87843144, 0.8313726 , 0.7843138 ],\n",
      "         ...,\n",
      "         [0.43921572, 0.40784317, 0.40000004],\n",
      "         [0.44705886, 0.4156863 , 0.40784317],\n",
      "         [0.43529415, 0.4039216 , 0.39607847]],\n",
      "\n",
      "        [[0.97647065, 0.9607844 , 0.86274517],\n",
      "         [0.9333334 , 0.882353  , 0.81568635],\n",
      "         [0.8862746 , 0.83921576, 0.77647066],\n",
      "         ...,\n",
      "         [0.44705886, 0.4156863 , 0.40784317],\n",
      "         [0.44705886, 0.4156863 , 0.40784317],\n",
      "         [0.4431373 , 0.41176474, 0.4039216 ]],\n",
      "\n",
      "        [[0.9843138 , 0.9686275 , 0.8705883 ],\n",
      "         [0.9568628 , 0.909804  , 0.8235295 ],\n",
      "         [0.91372555, 0.86274517, 0.78823537],\n",
      "         ...,\n",
      "         [0.454902  , 0.42352945, 0.4156863 ],\n",
      "         [0.454902  , 0.42352945, 0.4156863 ],\n",
      "         [0.44705886, 0.4156863 , 0.40784317]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.20392159, 0.28235295, 0.27450982],\n",
      "         [0.14901961, 0.227451  , 0.21960786],\n",
      "         [0.16862746, 0.22352943, 0.22352943],\n",
      "         ...,\n",
      "         [0.00784314, 0.08235294, 0.05882353],\n",
      "         [0.22352943, 0.31764707, 0.25490198],\n",
      "         [0.12156864, 0.18431373, 0.14117648]],\n",
      "\n",
      "        [[0.07058824, 0.15294118, 0.13333334],\n",
      "         [0.16862746, 0.2509804 , 0.23137257],\n",
      "         [0.21960786, 0.2784314 , 0.26666668],\n",
      "         ...,\n",
      "         [0.03529412, 0.1137255 , 0.07058824],\n",
      "         [0.20392159, 0.3019608 , 0.21568629],\n",
      "         [0.21568629, 0.28235295, 0.20784315]],\n",
      "\n",
      "        [[0.20784315, 0.2901961 , 0.2627451 ],\n",
      "         [0.18039216, 0.2627451 , 0.23529413],\n",
      "         [0.22352943, 0.28235295, 0.2627451 ],\n",
      "         ...,\n",
      "         [0.00392157, 0.08235294, 0.03529412],\n",
      "         [0.1764706 , 0.2784314 , 0.17254902],\n",
      "         [0.18823531, 0.25882354, 0.15686275]]],\n",
      "\n",
      "\n",
      "       [[[0.76470596, 0.64705884, 0.5529412 ],\n",
      "         [0.7568628 , 0.6392157 , 0.54509807],\n",
      "         [0.7411765 , 0.62352943, 0.5294118 ],\n",
      "         ...,\n",
      "         [0.6       , 0.6313726 , 0.44705886],\n",
      "         [0.5568628 , 0.58431375, 0.38431376],\n",
      "         [0.5882353 , 0.6156863 , 0.4156863 ]],\n",
      "\n",
      "        [[0.7686275 , 0.6509804 , 0.5568628 ],\n",
      "         [0.7607844 , 0.6431373 , 0.54901963],\n",
      "         [0.74509805, 0.627451  , 0.53333336],\n",
      "         ...,\n",
      "         [0.68235296, 0.7137255 , 0.5294118 ],\n",
      "         [0.6313726 , 0.65882355, 0.45882356],\n",
      "         [0.59607846, 0.62352943, 0.42352945]],\n",
      "\n",
      "        [[0.7686275 , 0.6509804 , 0.5568628 ],\n",
      "         [0.7607844 , 0.6431373 , 0.54901963],\n",
      "         [0.7490196 , 0.6313726 , 0.5372549 ],\n",
      "         ...,\n",
      "         [0.654902  , 0.6862745 , 0.5019608 ],\n",
      "         [0.62352943, 0.6509804 , 0.45098042],\n",
      "         [0.627451  , 0.654902  , 0.454902  ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.56078434, 0.4039216 , 0.16078432],\n",
      "         [0.6509804 , 0.5058824 , 0.3019608 ],\n",
      "         [0.00392157, 0.        , 0.04705883],\n",
      "         ...,\n",
      "         [0.50980395, 0.37254903, 0.24705884],\n",
      "         [0.6862745 , 0.57254905, 0.4156863 ],\n",
      "         [0.6666667 , 0.53333336, 0.38431376]],\n",
      "\n",
      "        [[0.5764706 , 0.4156863 , 0.24313727],\n",
      "         [0.67058825, 0.49411768, 0.2392157 ],\n",
      "         [0.02352941, 0.        , 0.03529412],\n",
      "         ...,\n",
      "         [0.50980395, 0.3803922 , 0.25882354],\n",
      "         [0.7960785 , 0.69411767, 0.5568628 ],\n",
      "         [0.6156863 , 0.49803925, 0.35686275]],\n",
      "\n",
      "        [[0.6156863 , 0.4431373 , 0.32941177],\n",
      "         [0.6039216 , 0.43529415, 0.21960786],\n",
      "         [0.44705886, 0.38431376, 0.25490198],\n",
      "         ...,\n",
      "         [0.6039216 , 0.48627454, 0.34509805],\n",
      "         [0.52156866, 0.41960788, 0.2901961 ],\n",
      "         [0.427451  , 0.3137255 , 0.15686275]]],\n",
      "\n",
      "\n",
      "       [[[0.9333334 , 0.8705883 , 0.8745099 ],\n",
      "         [0.92549026, 0.86274517, 0.86666673],\n",
      "         [0.9333334 , 0.8705883 , 0.8745099 ],\n",
      "         ...,\n",
      "         [0.7372549 , 0.61960787, 0.5254902 ],\n",
      "         [0.69803923, 0.64705884, 0.50980395],\n",
      "         [0.6862745 , 0.6627451 , 0.5294118 ]],\n",
      "\n",
      "        [[0.9294118 , 0.86666673, 0.87843144],\n",
      "         [0.92549026, 0.86274517, 0.8745099 ],\n",
      "         [0.9294118 , 0.86666673, 0.87843144],\n",
      "         ...,\n",
      "         [0.7058824 , 0.6       , 0.53333336],\n",
      "         [0.6666667 , 0.6313726 , 0.50980395],\n",
      "         [0.654902  , 0.6431373 , 0.5137255 ]],\n",
      "\n",
      "        [[0.9215687 , 0.86274517, 0.89019614],\n",
      "         [0.91372555, 0.854902  , 0.882353  ],\n",
      "         [0.9176471 , 0.8588236 , 0.8862746 ],\n",
      "         ...,\n",
      "         [0.6862745 , 0.60784316, 0.6039216 ],\n",
      "         [0.62352943, 0.6156863 , 0.5176471 ],\n",
      "         [0.61960787, 0.6431373 , 0.49411768]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.34117648, 0.37647063, 0.4431373 ],\n",
      "         [0.227451  , 0.23529413, 0.28627452],\n",
      "         [0.26666668, 0.27450982, 0.32156864],\n",
      "         ...,\n",
      "         [0.69411767, 0.6509804 , 0.7058824 ],\n",
      "         [0.75294125, 0.6745098 , 0.7176471 ],\n",
      "         [0.80392164, 0.69803923, 0.7254902 ]],\n",
      "\n",
      "        [[0.18039216, 0.22352943, 0.29411766],\n",
      "         [0.16862746, 0.16078432, 0.21568629],\n",
      "         [0.39607847, 0.37254903, 0.41960788],\n",
      "         ...,\n",
      "         [0.69803923, 0.627451  , 0.6745098 ],\n",
      "         [0.7686275 , 0.6666667 , 0.7019608 ],\n",
      "         [0.70980394, 0.6039216 , 0.62352943]],\n",
      "\n",
      "        [[0.11764707, 0.16078432, 0.23137257],\n",
      "         [0.19607845, 0.18039216, 0.2392157 ],\n",
      "         [0.4039216 , 0.36078432, 0.4156863 ],\n",
      "         ...,\n",
      "         [0.65882355, 0.5803922 , 0.627451  ],\n",
      "         [0.7490196 , 0.64705884, 0.68235296],\n",
      "         [0.7176471 , 0.61960787, 0.6431373 ]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[0.04313726, 0.01960784, 0.02745098],\n",
      "         [0.        , 0.        , 0.        ],\n",
      "         [0.00392157, 0.00392157, 0.00392157],\n",
      "         ...,\n",
      "         [0.36862746, 0.32156864, 0.36078432],\n",
      "         [0.34901962, 0.3019608 , 0.34117648],\n",
      "         [0.34901962, 0.3019608 , 0.34117648]],\n",
      "\n",
      "        [[0.05882353, 0.03529412, 0.04313726],\n",
      "         [0.        , 0.        , 0.        ],\n",
      "         [0.01176471, 0.01176471, 0.01176471],\n",
      "         ...,\n",
      "         [0.3529412 , 0.3019608 , 0.34117648],\n",
      "         [0.31764707, 0.26666668, 0.30588236],\n",
      "         [0.34509805, 0.29411766, 0.33333334]],\n",
      "\n",
      "        [[0.05490196, 0.03137255, 0.03921569],\n",
      "         [0.02745098, 0.02745098, 0.02745098],\n",
      "         [0.        , 0.        , 0.        ],\n",
      "         ...,\n",
      "         [0.34901962, 0.29803923, 0.3372549 ],\n",
      "         [0.3529412 , 0.3019608 , 0.34117648],\n",
      "         [0.37254903, 0.32156864, 0.36078432]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.21568629, 0.18823531, 0.21568629],\n",
      "         [0.18431373, 0.15686275, 0.18431373],\n",
      "         [0.13725491, 0.10980393, 0.13725491],\n",
      "         ...,\n",
      "         [0.12156864, 0.13333334, 0.15294118],\n",
      "         [0.14117648, 0.15294118, 0.18039216],\n",
      "         [0.10980393, 0.12156864, 0.15686275]],\n",
      "\n",
      "        [[0.14117648, 0.1137255 , 0.14117648],\n",
      "         [0.17254902, 0.14509805, 0.17254902],\n",
      "         [0.14509805, 0.11764707, 0.14509805],\n",
      "         ...,\n",
      "         [0.03921569, 0.0509804 , 0.07058824],\n",
      "         [0.10980393, 0.12156864, 0.14901961],\n",
      "         [0.09411766, 0.10588236, 0.14117648]],\n",
      "\n",
      "        [[0.1764706 , 0.14901961, 0.1764706 ],\n",
      "         [0.20392159, 0.1764706 , 0.20392159],\n",
      "         [0.17254902, 0.14509805, 0.17254902],\n",
      "         ...,\n",
      "         [0.1764706 , 0.18039216, 0.20000002],\n",
      "         [0.09019608, 0.10196079, 0.12941177],\n",
      "         [0.09019608, 0.11764707, 0.14901961]]],\n",
      "\n",
      "\n",
      "       [[[0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        ],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        ]],\n",
      "\n",
      "        [[0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        ],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        ]],\n",
      "\n",
      "        [[0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        ],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.00784314, 0.00392157, 0.        ],\n",
      "         [0.01568628, 0.        , 0.        ],\n",
      "         [0.01960784, 0.00392157, 0.        ],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        ]],\n",
      "\n",
      "        [[0.00784314, 0.00392157, 0.        ],\n",
      "         [0.00784314, 0.00392157, 0.        ],\n",
      "         [0.01960784, 0.00392157, 0.        ],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        ]],\n",
      "\n",
      "        [[0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        ],\n",
      "         [0.00392157, 0.00392157, 0.00392157],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        ]]],\n",
      "\n",
      "\n",
      "       [[[0.57254905, 0.14117648, 0.        ],\n",
      "         [0.5411765 , 0.1254902 , 0.02352941],\n",
      "         [0.4901961 , 0.12941177, 0.03921569],\n",
      "         ...,\n",
      "         [0.07058824, 0.03137255, 0.02745098],\n",
      "         [0.07058824, 0.03137255, 0.02745098],\n",
      "         [0.07058824, 0.03137255, 0.02745098]],\n",
      "\n",
      "        [[0.6117647 , 0.17254902, 0.        ],\n",
      "         [0.56078434, 0.13333334, 0.00392157],\n",
      "         [0.5058824 , 0.12941177, 0.03137255],\n",
      "         ...,\n",
      "         [0.07058824, 0.03137255, 0.02745098],\n",
      "         [0.06666667, 0.02745098, 0.02352941],\n",
      "         [0.06666667, 0.02745098, 0.02352941]],\n",
      "\n",
      "        [[0.7058824 , 0.24313727, 0.        ],\n",
      "         [0.63529414, 0.18823531, 0.        ],\n",
      "         [0.53333336, 0.12941177, 0.        ],\n",
      "         ...,\n",
      "         [0.07058824, 0.03137255, 0.02745098],\n",
      "         [0.07058824, 0.03137255, 0.02745098],\n",
      "         [0.07058824, 0.03137255, 0.02745098]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.01176471, 0.01176471, 0.01176471],\n",
      "         [0.00784314, 0.00784314, 0.00784314],\n",
      "         [0.01176471, 0.01176471, 0.01176471],\n",
      "         ...,\n",
      "         [0.00784314, 0.00784314, 0.00784314],\n",
      "         [0.00784314, 0.00784314, 0.00784314],\n",
      "         [0.00784314, 0.00784314, 0.00784314]],\n",
      "\n",
      "        [[0.00784314, 0.00784314, 0.00784314],\n",
      "         [0.00784314, 0.00784314, 0.00784314],\n",
      "         [0.00784314, 0.00784314, 0.00784314],\n",
      "         ...,\n",
      "         [0.00784314, 0.00784314, 0.00784314],\n",
      "         [0.01176471, 0.01176471, 0.01176471],\n",
      "         [0.00784314, 0.00784314, 0.00784314]],\n",
      "\n",
      "        [[0.00784314, 0.00784314, 0.00784314],\n",
      "         [0.00784314, 0.00784314, 0.00784314],\n",
      "         [0.00784314, 0.00784314, 0.00784314],\n",
      "         ...,\n",
      "         [0.00784314, 0.00784314, 0.00784314],\n",
      "         [0.01176471, 0.01176471, 0.01176471],\n",
      "         [0.00784314, 0.00784314, 0.00784314]]]], dtype=float32), array([[1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "val_batch = next(iter(validation_generator))\n",
    "print(val_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rakeem Shaikh\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - acc: 0.7199 - loss: 0.5595\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - acc: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python312\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - acc: 0.7998 - loss: 0.4086\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188us/step - acc: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - acc: 0.8517 - loss: 0.3937\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263us/step - acc: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - acc: 0.9053 - loss: 0.2430\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282us/step - acc: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - acc: 0.9222 - loss: 0.1957\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187us/step - acc: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - acc: 0.9052 - loss: 0.2763\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250us/step - acc: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - acc: 0.9065 - loss: 0.2350\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267us/step - acc: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - acc: 0.9271 - loss: 0.2247\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233us/step - acc: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - acc: 0.9285 - loss: 0.2004\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - acc: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - acc: 0.9111 - loss: 0.2210\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240us/step - acc: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - acc: 0.9229 - loss: 0.2092\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250us/step - acc: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - acc: 0.9332 - loss: 0.2100\n",
      "Epoch 24/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271us/step - acc: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 25/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - acc: 0.9258 - loss: 0.2154\n",
      "Epoch 26/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250us/step - acc: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 27/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - acc: 0.9395 - loss: 0.1829\n",
      "Epoch 28/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250us/step - acc: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 29/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - acc: 0.9420 - loss: 0.1672\n",
      "Epoch 30/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187us/step - acc: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 31/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - acc: 0.9454 - loss: 0.1647\n",
      "Epoch 32/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250us/step - acc: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 33/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - acc: 0.8999 - loss: 0.2022\n",
      "Epoch 34/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250us/step - acc: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 35/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - acc: 0.9288 - loss: 0.1900\n",
      "Epoch 36/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232us/step - acc: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 37/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - acc: 0.9487 - loss: 0.1592\n",
      "Epoch 38/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - acc: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 39/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - acc: 0.9377 - loss: 0.1588\n",
      "Epoch 40/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250us/step - acc: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 41/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - acc: 0.9424 - loss: 0.1553\n",
      "Epoch 42/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187us/step - acc: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 43/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - acc: 0.9431 - loss: 0.1622\n",
      "Epoch 44/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199us/step - acc: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 45/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - acc: 0.9499 - loss: 0.1395\n",
      "Epoch 46/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313us/step - acc: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 47/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - acc: 0.9543 - loss: 0.1243\n",
      "Epoch 48/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250us/step - acc: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 49/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - acc: 0.9569 - loss: 0.1311\n",
      "Epoch 50/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346us/step - acc: 0.0000e+00 - loss: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the entire model\n",
    "model.save('fire_detection_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Predicted class: fire\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load and preprocess the image\n",
    "img_path = 'Datasets/predict/fireimg2.jpeg'  # Replace with your image path\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array /= 255.0  # Rescale\n",
    "\n",
    "# Make the prediction\n",
    "predictions = model.predict(img_array)\n",
    "predicted_class = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['fire', 'no_fire']\n",
    "\n",
    "# Output the prediction\n",
    "print(\"Predicted class:\", class_names[predicted_class[0]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
